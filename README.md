# BentoML Local Setup (macOS - No Docker) with UV

ğŸš€ **Production-ready AI services** running locally on macOS with Apple Silicon optimization and UV package management.

## âœ¨ What This Gives You

- **ğŸ¨ Stable Diffusion Service** - Generate images from text prompts
- **ğŸ‘ï¸ LLaVA Vision Service** - Analyze images with structured JSON output
- **ğŸ¯ Whisper Audio Service** - Transcribe audio files and URLs
- **ğŸ“¸ Photo Upscaler Service** - AI-powered photo upscaling with Real-ESRGAN
- **ğŸ§  RAG Service** - Document ingestion and question-answering with retrieval-augmented generation
- **âš¡ Apple Silicon Optimized** - MPS acceleration for M1/M2/M3 Macs
- **ğŸ“¦ UV Package Management** - Lightning-fast dependency resolution
- **ğŸ”§ Zero Docker Required** - Pure Python with BentoML 1.4+

## ğŸƒâ€â™€ï¸ Quick Start

```bash
# 1. Setup (installs UV + dependencies)
./scripts/setup_env.sh

# 2. Verify setup
./scripts/check_setup.sh

# 3. Build and start all services
./scripts/build_services.sh
./scripts/start.sh

# 4. Check service health
./scripts/health.sh
```

Then visit: **http://127.0.0.1:3000/docs** for the interactive API!

## ğŸº Homebrew Service (macOS)

To run as a system service using Homebrew:

```bash
# 1. Install as a Homebrew service
brew install --formula ./config/brew-bentoml-service.rb

# 2. Start the service
brew services start bentoml-multiservice

# 3. Check service status
brew services list | grep bentoml

# 4. Stop the service
brew services stop bentoml-multiservice

# 5. View service logs
tail -f /opt/homebrew/var/log/bentoml-multiservice.log
```

The service will automatically start on boot and restart if it crashes.

## ğŸ¯ Available Services

| Service | What it does | Build & Serve |
|---------|-------------|---------------|
| **Stable Diffusion** | Text â†’ Image generation | `BENTOFILE=config/bentofiles/stable-diffusion.yaml ./scripts/run_bentoml.sh build services/stable_diffusion_service.py` |
| **LLaVA Vision** | Image + Text â†’ JSON analysis | `BENTOFILE=config/bentofiles/llava.yaml ./scripts/run_bentoml.sh build services/llava_service.py` |
| **Whisper Audio** | Audio â†’ Text transcription | `BENTOFILE=config/bentofiles/whisper.yaml ./scripts/run_bentoml.sh build services/whisper_service.py` |
| **Photo Upscaler** | Image â†’ AI upscaled image | `BENTOFILE=config/bentofiles/upscaler.yaml ./scripts/run_bentoml.sh build services/upscaler_service.py` |
| **RAG Service** | Document ingestion + Q&A | `BENTOFILE=config/bentofiles/rag.yaml ./scripts/run_bentoml.sh build services/rag_service.py` |
| **Example** | Simple API for testing | `./scripts/run_bentoml.sh build services/example_service.py` |

### Testing Endpoints

Use the endpoint testing script for interactive API testing:

```bash
# Test health check
./scripts/endpoint.sh health '{}'

# Test hello service with custom name
./scripts/endpoint.sh hello '{"name": "BentoML"}'

# Test with empty payload (uses defaults)
./scripts/endpoint.sh hello '{}'

# Test Stable Diffusion image generation
./scripts/endpoint.sh generate_image '{"prompt": "A beautiful sunset", "width": 512, "height": 512}'

# Test LLaVA image analysis (base64/bytes)
./scripts/endpoint.sh analyze_image '{"image": "base64...", "prompt": "What is in this image?"}'

# Test LLaVA image analysis from URL
./scripts/endpoint.sh analyze_image_url '{"image_url": "https://plufz.com/test-assets/test-office.jpg", "prompt": "What is in this image?"}'

# Test Whisper audio transcription from URL
./scripts/endpoint.sh transcribe_url '{"url": "https://plufz.com/test-assets/test-english.mp3"}'

# Test Whisper audio transcription from file (requires curl for file upload)
curl -X POST http://127.0.0.1:3000/transcribe_file \
  -F "audio_file=@./test-assets/test-english.mp3"

# Test Photo Upscaler from URL
./scripts/endpoint.sh upscale_url '{"url": "https://plufz.com/test-assets/test-office.jpg", "scale_factor": 2.0}'

# Test Photo Upscaler from file (requires curl for file upload)
curl -X POST http://127.0.0.1:3000/upscale_file \
  -F "image_file=@./test-assets/test-upscale.jpg" \
  -F "scale_factor=2.5" \
  -F "output_format=PNG"

# Test RAG document ingestion (text)
./scripts/endpoint.sh rag_ingest_text '{"text": "This is a test document about AI.", "metadata": {"source": "test"}}'

# Test RAG query
./scripts/endpoint.sh rag_query '{"query": "What is AI?", "max_tokens": 512}'

# Use custom host/port and verbose output
./scripts/endpoint.sh health '{}' --host localhost --port 3001 --verbose

# Get help with available endpoints
./scripts/endpoint.sh --help
```

**Note**: Image endpoints (generate_image, upscale_*) automatically extract base64 image data and save actual image files to `endpoint_images/` directory, providing clean JSON output.

## ğŸ“š Complete Documentation

**ğŸ“– [Full Documentation in `docs/`](docs/README.md)**

### ğŸš€ Getting Started
- **[Quick Start Guide](docs/quick-start.md)** - Up and running in 5 minutes
- **[Installation & Setup](docs/installation.md)** - Detailed installation
- **[Configuration](docs/configuration.md)** - Customize your setup

### ğŸ¤– AI Services  
- **[Stable Diffusion Service](docs/services/stable-diffusion.md)** - Text-to-image generation
- **[LLaVA Service](docs/services/llava-service.md)** - Vision-language analysis
- **[Testing Guide](docs/testing.md)** - pytest test suite and legacy scripts

### ğŸ”§ Advanced
- **[API Reference](docs/api-reference.md)** - Complete API docs
- **[Utilities Documentation](docs/utilities.md)** - Reusable components
- **[Troubleshooting](docs/troubleshooting.md)** - Fix common issues

## ğŸ—ï¸ Project Structure

```
bentoml-project/
â”œâ”€â”€ docs/                 # ğŸ“š Complete documentation
â”œâ”€â”€ scripts/             # ğŸ› ï¸ Management scripts  
â”‚   â”œâ”€â”€ run_bentoml.sh   # Build & serve services
â”‚   â”œâ”€â”€ check_setup.sh   # Verify installation
â”‚   â””â”€â”€ test_*.sh        # Legacy test scripts (deprecated)
â”œâ”€â”€ tests/               # ğŸ§ª Pytest test suite (recommended)
â”‚   â”œâ”€â”€ conftest.py      # Shared test fixtures
â”‚   â”œâ”€â”€ test_example_service.py
â”‚   â”œâ”€â”€ test_llava_service.py
â”‚   â”œâ”€â”€ test_stable_diffusion_service.py
â”‚   â”œâ”€â”€ test_whisper_service.py
â”‚   â””â”€â”€ test_multi_service.py
â”œâ”€â”€ services/            # ğŸ¤– AI services
â”‚   â”œâ”€â”€ stable_diffusion_service.py
â”‚   â”œâ”€â”€ llava_service.py
â”‚   â”œâ”€â”€ whisper_service.py
â”‚   â”œâ”€â”€ multi_service.py
â”‚   â””â”€â”€ example_service.py
â”œâ”€â”€ utils/               # ğŸ”§ Reusable utilities
â”‚   â”œâ”€â”€ stable_diffusion/ # SD pipeline utilities
â”‚   â””â”€â”€ llava/           # LLaVA utilities
â””â”€â”€ config/              # âš™ï¸ Service configurations
    â”œâ”€â”€ bentoml.yaml     # Server config
    â””â”€â”€ bentofiles/      # Service build configs
```

## ğŸ¨ Example Usage

### Generate an Image
```bash
curl -X POST http://127.0.0.1:3000/generate_image \
  -H "Content-Type: application/json" \
  -d '{"request": {"prompt": "a cute cat in a garden"}}' \
  | jq -r '.image' | base64 -d > cat.png
```

### Analyze an Image (PNG)
```bash  
curl -X POST http://127.0.0.1:3000/analyze_image \
  -H "Content-Type: application/json" \
  -d '{
    "request": {
      "prompt": "What objects are in this image?",
      "image": "https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Vd-Orig.png/256px-Vd-Orig.png",
      "json_schema": {
        "type": "object", 
        "properties": {
          "objects": {"type": "array", "items": {"type": "string"}}
        }
      }
    }
  }'
```

### Analyze a JPEG Image
```bash
curl -X POST http://127.0.0.1:3000/analyze_image \
  -H "Content-Type: application/json" \
  -d '{
    "request": {
      "prompt": "Describe what you see in this image",
      "image": "https://httpbin.org/image/jpeg"
    }
  }' | jq '.response'
```

## ğŸ§ª Testing Your Services

### Recommended: pytest (Official BentoML Testing)

**Using the test script (easiest):**
```bash
./scripts/test.sh                    # Fast tests only
./scripts/test.sh --all              # All tests including slow integration  
./scripts/test.sh --coverage         # Fast tests with coverage
./scripts/test.sh --service example  # Test specific service
./scripts/test.sh --unit             # Unit tests only
./scripts/test.sh --help             # Show all options
```

**Direct UV commands:**
```bash
# Run all fast tests (unit + behavior)
uv run pytest -m "not slow"

# Run all tests including slow integration tests
uv run pytest

# Run specific service tests
uv run pytest tests/test_example_service.py

# Run with coverage report
uv run pytest --cov=. --cov-report=term-missing
```

### Legacy: Bash Scripts (Deprecated)
```bash
./scripts/test_service.sh          # Basic service test
./scripts/test_llava.sh           # LLaVA service test
./scripts/test_multi_service.sh   # Multi-service test
```

**âœ¨ The pytest suite includes:**
- **Unit Tests** - Test individual methods with mocked dependencies
- **Integration Tests** - Test actual service startup and API endpoints
- **HTTP Behavior Tests** - Test response formats and error handling
- **62% Code Coverage** - Comprehensive test coverage across all services

## âš¡ Key Features

- **ğŸ Apple Silicon Optimized** - Uses MPS backend with float32 for stability
- **ğŸ’¾ External Drive Support** - Custom HF_HOME for model storage
- **ğŸ”„ Auto Device Detection** - MPS â†’ CUDA â†’ CPU fallback
- **ğŸ“Š Structured Output** - JSON schema validation for LLaVA
- **ğŸ§ª Professional Testing** - pytest-based test suite following BentoML best practices
- **ğŸ“ˆ Modular Architecture** - Reusable utilities for easy extension

## ğŸ› ï¸ Requirements

- **macOS** (Apple Silicon recommended)
- **Python 3.8+**  
- **8GB+ RAM** (16GB for LLaVA)
- **20GB+ storage** (for AI models)

## ğŸš¨ Need Help?

- **Quick Issues**: Check **[Troubleshooting Guide](docs/troubleshooting.md)**
- **Service Docs**: See **[docs/](docs/README.md)** for complete guides  
- **Getting Started**: Follow **[Quick Start](docs/quick-start.md)**

---

**Built with** â¤ï¸ **using BentoML, UV, and optimized for Apple Silicon**